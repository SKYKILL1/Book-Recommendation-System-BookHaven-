{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08d8038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the necessary libraries required to create the model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "#Load the dataset\n",
    "books = pd.read_csv('./Dataset/books.csv')\n",
    "books_new = pd.read_csv('./Dataset/books_new.csv')\n",
    "\n",
    "#checking the loaded dataset1\n",
    "print(books)\n",
    "\n",
    "#checking the loaded dataset2\n",
    "print(books_new)\n",
    "\n",
    "# Merging both the datasets \n",
    "df = pd.concat([books,books_new])\n",
    "\n",
    "df\n",
    "\n",
    "# Checking For null Values\n",
    "df.isna().sum()\n",
    "\n",
    "# Checking For data distribution and some statistics\n",
    "df.describe()\n",
    "\n",
    "#dropping duplicate rows if any\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Checking whether there were any duplicates or not\n",
    "df.shape\n",
    "\n",
    "# Filling Null Values with Unknown Value\n",
    "df['SubGenre'] = df['SubGenre'].fillna('Unknown')\n",
    "\n",
    "df\n",
    "\n",
    "# Filling Null Values with Unknown Value\n",
    "df['Author'] = df['Author'].fillna('Unknown Author')\n",
    "\n",
    "# Filling Null Values with Unknown Value\n",
    "df['Publisher'] = df['Publisher'].fillna('Unknown Publisher')\n",
    "\n",
    "df\n",
    "\n",
    "# Checking if all the null values are filled\n",
    "df.info()\n",
    "\n",
    "#copying data into another variable to try some ideas\n",
    "df1 = df.copy()\n",
    "\n",
    "# Trying to fill SubGenre Null values to a predicted subgenre value\n",
    "\n",
    "\n",
    "#label endoding the categorical fields\n",
    "labelencoders = {}\n",
    "categorical_columns = ['Title','Author','Genre','Publisher','SubGenre']\n",
    "\n",
    "for columns in categorical_columns:\n",
    "    labelencoders[columns] = LabelEncoder()\n",
    "    df1[columns] = labelencoders[columns].fit_transform(df1[columns])\n",
    "    \n",
    "# creating different variables to distinguish null valued subgenre rows and non-null value rows    \n",
    "books_unknown = df1[df1.SubGenre ==0]\n",
    "books_known = df1[df1['SubGenre']!=0]\n",
    "\n",
    "#label encoding subgenre column in known subgenre variable\n",
    "subgenre_encoder = LabelEncoder()\n",
    "subgenre_endocded = subgenre_encoder.fit_transform(books_known['SubGenre'])\n",
    "\n",
    "# preparing training and testing data for training and testing\n",
    "X = books_known.drop(columns = ['SubGenre'])\n",
    "y = books_known['SubGenre']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "\n",
    "# training the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#testing the model\n",
    "X_unknown = books_unknown.drop(columns=['SubGenre'])\n",
    "\n",
    "books_unknown['SubGenre'] = subgenre_encoder.inverse_transform(clf.predict(X_unknown))\n",
    "\n",
    "# Combined the datasets back\n",
    "df2 = pd.concat([books_known, books_unknown])\n",
    "\n",
    "#converted back the categorical features to original labels\n",
    "for column in categorical_columns:\n",
    "    df2[column] = labelencoders[column].inverse_transform(df2[column])\n",
    "\n",
    "# Output of cleaned dataset\n",
    "print(df2.head())\n",
    "\n",
    "# printing the new dataframe\n",
    "df2\n",
    "\n",
    "df2['GenreCombined'] = df2['Genre'] + ',' + df2['SubGenre']\n",
    "\n",
    "df2\n",
    "\n",
    "# Again Copying the dataset\n",
    "\n",
    "df3 = df2.copy()\n",
    "df3\n",
    "\n",
    "# combining Genre and SubGenre Columns\n",
    "df3['GenreCombined'].replace(r',Unknown',r'',regex=True,inplace=True)\n",
    "\n",
    "df3\n",
    "\n",
    "# Dropping Genre and SubGenre columns because they are not needed anymore\n",
    "df3.drop(columns=['Genre','SubGenre'],inplace=True)\n",
    "\n",
    "df3.to_csv('./Dataset/Books_merged.csv',)\n",
    "\n",
    "df3\n",
    "\n",
    "# # Used TF-IDF Vectorizer to convert genre_combined into a matrix of token counts\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df3['GenreCombined'])\n",
    "\n",
    "# finding similarity between all books based on Genre\n",
    "similarity= cosine_similarity(tfidf_matrix,tfidf_matrix)\n",
    "\n",
    "print(list(enumerate(similarity)))\n",
    "\n",
    "# Function to get book recommendations based on genre and sub-genre\n",
    "def get_recommendations(title, cosine_sim=similarity):\n",
    "    # Get the index of the book that matches the title\n",
    "    index = df3[df3['Title'] == title].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores of all books with that book\n",
    "    similarity_scores = list(enumerate(cosine_sim[index]))\n",
    "\n",
    "    # Sort the books based on the similarity scores\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the 10 most similar books\n",
    "    similarity_indices = [i[0] for i in similarity_scores[1:8]]\n",
    "\n",
    "    # Return the top 10 most similar books\n",
    "    return df3.iloc[similarity_indices]\n",
    "\n",
    "\n",
    "# Testing the model\n",
    "\n",
    "recommendation = get_recommendations('Data Smart')\n",
    "\n",
    "recommendation\n",
    "\n",
    "recommendation2 = get_recommendations('Orientalism')\n",
    "recommendation2\n",
    "\n",
    "recommendation3 = get_recommendations('Fundamentals of Wavelets')\n",
    "recommendation3\n",
    "\n",
    "genre_books = df3[df3['GenreCombined'].str.contains('data_science', case=False)]\n",
    "\n",
    "\n",
    "def get_genre_recommendations(input_genre):\n",
    "    # Filter books based on the input genre\n",
    "    genre_books = df3[df3['GenreCombined'].str.contains(input_genre, case=False)]\n",
    "    \n",
    "    # Check if the genre exists in the dataset\n",
    "    if genre_books.empty:\n",
    "        print(f\"No books found for the genre '{input_genre}'.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get indices of books that match the input genre\n",
    "    genre_indices = genre_books.index\n",
    "    \n",
    "    index_list = genre_books.index\n",
    "\n",
    "    Title = df3.iloc[index_list[0]]['Title']\n",
    "    \n",
    "    recommendations = get_recommendations(Title)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example: Get recommendations for a specific genre\n",
    "input_genre = 'data_science'\n",
    "recommendations = get_genre_recommendations(input_genre)\n",
    "recommendations\n",
    "# Display the recommended books if found\n",
    "# if not recommendations.empty:\n",
    "#     for i in recommendations:\n",
    "#         print(i)\n",
    "\n",
    "# Encode the Author's name\n",
    "label_encoder = LabelEncoder()\n",
    "df3['Author_encoded'] = label_encoder.fit_transform(df3['Author'].astype(str))\n",
    "\n",
    "# Use TF-Idf3 Vectorizer to convert GenreCombined into a matrix of token counts\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df3['GenreCombined'])\n",
    "\n",
    "# Reshape Author_encoded to be a 2D array (required for cosine_similarity)\n",
    "Author_encoded_reshaped = df3['Author_encoded'].values.reshape(-1, 1)\n",
    "\n",
    "# Compute cosine similarity between all books based on GenreCombined and Authors\n",
    "cosine_sim_genre = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim_Author = cosine_similarity(Author_encoded_reshaped, Author_encoded_reshaped)\n",
    "\n",
    "# Function to get book recommendations based on genre, title, and Author\n",
    "def get_recommendations(title, input_genre=None, input_Author=None, df3=df3, cosine_sim_genre=cosine_sim_genre, cosine_sim_Author=cosine_sim_Author):\n",
    "    # Check if the title exists in the dataset\n",
    "    if title not in df3['Title'].values:\n",
    "        print(f\"The book titled '{title}' was not found in the dataset.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get the index of the book that matches the title\n",
    "    idx = df3[df3['Title'] == title].index[0]\n",
    "\n",
    "    # Initialize a list to store the final similarity scores\n",
    "    final_sim_scores = []\n",
    "\n",
    "    # Calculate similarity scores based on genre\n",
    "    if input_genre:\n",
    "        genre_books = df3[df3['GenreCombined'].str.contains(input_genre, case=False)]\n",
    "        genre_indices = genre_books.index\n",
    "        genre_sim_scores = list(enumerate(cosine_sim_genre[idx]))\n",
    "        genre_sim_scores = [score for score in genre_sim_scores if score[0] in genre_indices]\n",
    "        final_sim_scores.extend(genre_sim_scores)\n",
    "\n",
    "    # Calculate similarity scores based on Author\n",
    "    if input_Author:\n",
    "        Author_books = df3[df3['Author'] == input_Author]\n",
    "        Author_indices = Author_books.index\n",
    "        Author_sim_scores = enumerate(cosine_sim_Author[idx])\n",
    "        Author_sim_scores = listt()\n",
    "        Author_sim_scores = [score for score in Author_sim_scores if score[0] in Author_indices]\n",
    "        final_sim_scores.extend(Author_sim_scores)\n",
    "\n",
    "    # Calculate similarity scores based on title (same genre and Author)\n",
    "    title_sim_scores = list(enumerate((cosine_sim_genre[idx] + cosine_sim_Author[idx]) / 2))\n",
    "    final_sim_scores.extend(title_sim_scores)\n",
    "\n",
    "    # Remove duplicates and sort the books based on the combined similarity scores\n",
    "    final_sim_scores = list(set(final_sim_scores))\n",
    "    final_sim_scores = sorted(final_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the top 10 most similar books\n",
    "    sim_indices = [i[0] for i in final_sim_scores[1:7]]\n",
    "\n",
    "    # Return the top 10 most similar books\n",
    "    return df3.iloc[sim_indices]\n",
    "\n",
    "# Example: Get recommendations for a specific book title, genre, and Author\n",
    "book_title = 'Data Smart'\n",
    "input_genre = 'data_science'\n",
    "input_Author = 'John'\n",
    "recommendations = get_recommendations(book_title, input_genre, input_Author)\n",
    "\n",
    "# Display the recommended books if found\n",
    "if not recommendations.empty:\n",
    "    print(recommendations[['Title', 'Author', 'GenreCombined', 'Publisher', 'Height']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "424bd769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atifa\\AppData\\Local\\Temp\\ipykernel_16564\\871374076.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  books_unknown['SubGenre'] = subgenre_encoder.inverse_transform(clf.predict(X_unknown))\n"
     ]
    }
   ],
   "source": [
    "#importing all the necessary libraries required to create the model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "#Load the dataset\n",
    "books = pd.read_csv('./Dataset/books.csv')\n",
    "books_new = pd.read_csv('./Dataset/books_new.csv')\n",
    "\n",
    "\n",
    "# Merging both the datasets \n",
    "df = pd.concat([books,books_new])\n",
    "\n",
    "#dropping duplicate rows if any\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Filling Null Values with Unknown Value\n",
    "df['SubGenre'] = df['SubGenre'].fillna('Unknown')\n",
    "\n",
    "\n",
    "# Filling Null Values with Unknown Value\n",
    "df['Author'] = df['Author'].fillna('Unknown Author')\n",
    "\n",
    "# Filling Null Values with Unknown Value\n",
    "df['Publisher'] = df['Publisher'].fillna('Unknown Publisher')\n",
    "\n",
    "\n",
    "#copying data into another variable to try some ideas\n",
    "df1 = df.copy()\n",
    "\n",
    "# Trying to fill SubGenre Null values to a predicted subgenre value\n",
    "\n",
    "\n",
    "#label endoding the categorical fields\n",
    "labelencoders = {}\n",
    "categorical_columns = ['Title','Author','Genre','Publisher','SubGenre']\n",
    "\n",
    "for columns in categorical_columns:\n",
    "    labelencoders[columns] = LabelEncoder()\n",
    "    df1[columns] = labelencoders[columns].fit_transform(df1[columns])\n",
    "    \n",
    "# creating different variables to distinguish null valued subgenre rows and non-null value rows    \n",
    "books_unknown = df1[df1.SubGenre ==0]\n",
    "books_known = df1[df1['SubGenre']!=0]\n",
    "\n",
    "#label encoding subgenre column in known subgenre variable\n",
    "subgenre_encoder = LabelEncoder()\n",
    "subgenre_endocded = subgenre_encoder.fit_transform(books_known['SubGenre'])\n",
    "\n",
    "# preparing training and testing data for training and testing\n",
    "X = books_known.drop(columns = ['SubGenre'])\n",
    "y = books_known['SubGenre']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=5)\n",
    "\n",
    "# training the model\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#testing the model\n",
    "X_unknown = books_unknown.drop(columns=['SubGenre'])\n",
    "\n",
    "books_unknown['SubGenre'] = subgenre_encoder.inverse_transform(clf.predict(X_unknown))\n",
    "\n",
    "# Combined the datasets back\n",
    "df2 = pd.concat([books_known, books_unknown])\n",
    "\n",
    "#converted back the categorical features to original labels\n",
    "for column in categorical_columns:\n",
    "    df2[column] = labelencoders[column].inverse_transform(df2[column])\n",
    "\n",
    "\n",
    "df2['GenreCombined'] = df2['Genre'] + ',' + df2['SubGenre']\n",
    "\n",
    "\n",
    "# Again Copying the dataset\n",
    "\n",
    "df3 = df2.copy()\n",
    "\n",
    "\n",
    "# combining Genre and SubGenre Columns\n",
    "df3['GenreCombined'].replace(r',Unknown',r'',regex=True,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Dropping Genre and SubGenre columns because they are not needed anymore\n",
    "df3.drop(columns=['Genre','SubGenre'],inplace=True)\n",
    "\n",
    "# # Used TF-IDF Vectorizer to convert genre_combined into a matrix of token counts\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df3['GenreCombined'])\n",
    "\n",
    "# finding similarity between all books based on Genre\n",
    "similarity= cosine_similarity(tfidf_matrix,tfidf_matrix)\n",
    "\n",
    "\n",
    "genre_books = df3[df3['GenreCombined'].str.contains('data_science', case=False)]\n",
    "\n",
    "\n",
    "# Encode the Author's name\n",
    "label_encoder = LabelEncoder()\n",
    "df3['Author_encoded'] = label_encoder.fit_transform(df3['Author'].astype(str))\n",
    "\n",
    "# Use TF-Idf3 Vectorizer to convert GenreCombined into a matrix of token counts\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df3['GenreCombined'])\n",
    "\n",
    "# Reshape Author_encoded to be a 2D array (required for cosine_similarity)\n",
    "Author_encoded_reshaped = df3['Author_encoded'].values.reshape(-1, 1)\n",
    "\n",
    "# Compute cosine similarity between all books based on GenreCombined and Authors\n",
    "cosine_sim_genre = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim_Author = cosine_similarity(Author_encoded_reshaped, Author_encoded_reshaped)\n",
    "\n",
    "# Function to get book recommendations based on genre, title, and Author\n",
    "def get_recommendations(title, input_genre=None, input_Author=None, df3=df3, cosine_sim_genre=cosine_sim_genre, cosine_sim_Author=cosine_sim_Author):\n",
    "    # Check if the title exists in the dataset\n",
    "    if title not in df3['Title'].values:\n",
    "        print(f\"The book titled '{title}' was not found in the dataset.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Get the index of the book that matches the title\n",
    "    idx = df3[df3['Title'] == title].index[0]\n",
    "\n",
    "    # Initialize a list to store the final similarity scores\n",
    "    final_sim_scores = []\n",
    "\n",
    "    # Calculate similarity scores based on genre\n",
    "    if input_genre:\n",
    "        genre_books = df3[df3['GenreCombined'].str.contains(input_genre, case=False)]\n",
    "        genre_indices = genre_books.index\n",
    "        genre_sim_scores = list(enumerate(cosine_sim_genre[idx]))\n",
    "        genre_sim_scores = [score for score in genre_sim_scores if score[0] in genre_indices]\n",
    "        final_sim_scores.extend(genre_sim_scores)\n",
    "\n",
    "    # Calculate similarity scores based on Author\n",
    "    if input_Author:\n",
    "        Author_books = df3[df3['Author'] == input_Author]\n",
    "        Author_indices = Author_books.index\n",
    "        Author_sim_scores = enumerate(cosine_sim_Author[idx])\n",
    "        Author_sim_scores = list(Author_sim_scores)\n",
    "        Author_sim_scores = [score for score in Author_sim_scores if score[0] in Author_indices]\n",
    "        final_sim_scores.extend(Author_sim_scores)\n",
    "\n",
    "    # Calculate similarity scores based on title (same genre and Author)\n",
    "    title_sim_scores = list(enumerate((cosine_sim_genre[idx] + cosine_sim_Author[idx]) / 2))\n",
    "    final_sim_scores.extend(title_sim_scores)\n",
    "\n",
    "    # Remove duplicates and sort the books based on the combined similarity scores\n",
    "    final_sim_scores = list(set(final_sim_scores))\n",
    "    final_sim_scores = sorted(final_sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the top 10 most similar books\n",
    "    sim_indices = [i[0] for i in final_sim_scores[1:7]]\n",
    "\n",
    "    # Return the top 10 most similar books\n",
    "    return df3.iloc[sim_indices]\n",
    "\n",
    "\n",
    "# Testing the model\n",
    "\n",
    "# Example: Get recommendations for a specific book title, genre, and Author\n",
    "book_title = 'Data Smart'\n",
    "input_genre = 'data_science'\n",
    "input_Author = 'John'\n",
    "recommendations = get_recommendations(book_title, input_genre, input_Author)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7336f8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Height</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>GenreCombined</th>\n",
       "      <th>Author_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Signal and the Noise, The</td>\n",
       "      <td>Silver, Nate</td>\n",
       "      <td>233</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>tech,data_science</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Neural Networks</td>\n",
       "      <td>Haykin, Simon</td>\n",
       "      <td>240</td>\n",
       "      <td>Unknown Publisher</td>\n",
       "      <td>tech,data_science</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Statistical Learning Theory</td>\n",
       "      <td>Vapnik, Vladimir</td>\n",
       "      <td>228</td>\n",
       "      <td>Unknown Publisher</td>\n",
       "      <td>tech,data_science</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientists at Work</td>\n",
       "      <td>Sebastian Gutierrez</td>\n",
       "      <td>230</td>\n",
       "      <td>Apress</td>\n",
       "      <td>tech,data_science</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Machine Learning for Hackers</td>\n",
       "      <td>Conway, Drew</td>\n",
       "      <td>233</td>\n",
       "      <td>O'Reilly</td>\n",
       "      <td>tech,data_science</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nature of Statistical Learning Theory, The</td>\n",
       "      <td>Vapnik, Vladimir</td>\n",
       "      <td>230</td>\n",
       "      <td>Springer</td>\n",
       "      <td>tech,data_science</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title               Author  Height  \\\n",
       "23                    Signal and the Noise, The         Silver, Nate     233   \n",
       "157                             Neural Networks        Haykin, Simon     240   \n",
       "160                 Statistical Learning Theory     Vapnik, Vladimir     228   \n",
       "10                      Data Scientists at Work  Sebastian Gutierrez     230   \n",
       "22                 Machine Learning for Hackers         Conway, Drew     233   \n",
       "5    Nature of Statistical Learning Theory, The     Vapnik, Vladimir     230   \n",
       "\n",
       "             Publisher      GenreCombined  Author_encoded  \n",
       "23             Penguin  tech,data_science             106  \n",
       "157  Unknown Publisher  tech,data_science              57  \n",
       "160  Unknown Publisher  tech,data_science             120  \n",
       "10              Apress  tech,data_science             103  \n",
       "22            O'Reilly  tech,data_science              13  \n",
       "5             Springer  tech,data_science             120  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5432d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
